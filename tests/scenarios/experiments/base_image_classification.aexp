# ###################################################################
#                  Base Image Classification Experiment
# This just creates a model and a dataset with no Attack
# or defense
####################################################################
---
_meta:
  name: base_image_classification.json
  author: S. Henshaw
  description: Blah

poison: null

attack:
  knowledge: "white"
  kwargs:
    batch_size: 1
    eps: 0.2
    eps_step: 0.1
    minimal: false
    num_random_init: 0
    targeted: false
  module: "art.attacks.evasion"
  name: "FastGradientMethod"
  use_label: true

dataset:
  batch_size: 64
  framework: "numpy"
  module: "armory.engine.data.datasets"
  name: "mnist"

defense: null
metric:
  means: true
  perturbation: "linf"
  record_metric_per_sample: false
  task: ["categorical_accuracy"]

model:
  fit: true
  fit_kwargs:
    nb_epochs: 3
  model_kwargs: {}
  module: "armory.engine.baseline_models.pytorch.mnist"
  name: "get_art_model"
  weights_file: null
  wrapper_kwargs: {}

scenario:
  kwargs: null
  module_name: "armory.engine.scenarios.image_classification"
  function_name: "ImageClassificationTask"

execution:
  mode: "docker"
  docker_image: "testtorch"

environment:
  credentials:
    git_token: "foo"